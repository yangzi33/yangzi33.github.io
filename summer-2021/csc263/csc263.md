---
layout: page
title: CSC263 Notes
permalink: /summer-2021/csc263/csc263
tags: summer, 2021
---

<style>
    ul {
      margin-bottom: 0;
    }
</style>

## Lecture 1

### What is a Data Structure

1. ADT = Set of objects together with operations
   1. Objects -> Integers -> Add, subtract, ...
   2. Stacks -> a pile of items -> push, pop, isEmpty
2. Data Structure = Implementation of an ADT, a way to represent objects and an algorithm for every operation
   1. Linked Lists
      Push: Insert at head
      isEmpty: Head == NULL
      pop: return head, reassign head pointer
   2. Arrays
      push: put new item at size; increment size
      pop: return whats at size; decrement size

### Runtime Complexity Abstractons

1. **Complexity**: amount of resources required by an algorithm, measured as a *function of input size*
2. **Resources**: time or space (memory)
3. **Input Size is problem dependent**
   1. Numbers: size = number of bits
   2. Lists: size = number of elements/length
   3. Graphs: size = number of edges / number of vertices

### Analyzing Runtime Complexity

1. **Asymptotic Notation**
   1. Big O
   2. Big Omega
   3. Big Theta
2. **Runtime Cases**
   1. Best cases
   2. Average case
   3. Worst case

#### Asymptotic Notation (Intuitively)

1. **Big-Oh**: $f(n)=O(g(n))$ means that the function $f(n)$ grows slower or at the same rate as $g(n)$.
2. **Big-Omega**: $f(n)=\Omega(g(n))$ means htat the function $f(n)$ grows faster or at the same rate as $g(n)$.
3. **BIg-Theta**: $f(n) = \Theta(g(n))$ means that the function $f(n)$ grows at the same rate as $g(n)$.

#### Asymptotic Notation (Practically)

1. In practice:
   1. Big-O: argue that the algorithm executes no more that $c\cdot g(n)$ steps **on every input** of size $n$.
   2. Big-Omega: argue that ...
2. We can't always find a tight bound

### Worst-case Analysis Example

```pseudocode
def hasTwentyOne(L):
    j = L.head
    while j != None and j.key != 21:
        j = j.next
    return
```

1. What is $n$? Input size = length of L = # of elements in list
2. Operations of interest? Comparisons
   1. Line 3: 2 comparisons
3. Just for completeness, when does the best case happen?
   1. **Correct but not an accepted answer: List is empty (**Not accepted in this course**)
   2. **Answer**: First element is 21
4. Worst case: 21 not in the lists
   1. $2n+1$ operations
   2. The loop executes at most one time per element, and line 3 advances it to the next element every time. So it cannot execute more that $n$ times
      1. ^ An argument that it is the worst case, i.e. no other case could take longer
   3. We can conclude that the worst case is $\Theta(n)$
5. The number of comparisons depends on when we see 21 *for the first time*

6. Suppose the first occurence of 21 happens at index $k$
   1. $k$ comparisons

### Average-case Analysis

1. For algorithm $A$, define
   $$
   \begin{align}
   S_n&=\mbox{sample space of all inputs of size }n\\
   t_n(x)&=\mbox{number rof steps executed by $A$ on input $x\in S_n$}\\
   T_{avg}(n)&=\mbox{the (weighted) average of the algorithm's running time for all inputs fo size }n
   \end{align}
   $$

2. Average-case Running time is the *expectation* of the running time as distributed over all possible values of $T$:
   $$
   \mathbb{E}(T)=\sum_t t\cdot\mbox{Pr}(T=t)
   $$

3. Average-case example for (fill this)
   $$
   \begin{align}
   \mathbb{E}(t) &= \sum_{\mbox{all cases}} Pr(T=t)\cdot t\\
   &=Pr(\mbox{21 not in list})(2n+1)+\sum^n_{k=1}Pr(\mbox{first 21 at pos }k)(2k)\\
   &=(1-p)^n(2n+1)+\sum^n_{k=1}(1-p)^{k-1}p(2k)\\
   &=(1-p)^n(2n+1)+\frac{2p}{1-p}\sum^n_{k=1}(1-p)^k\\
   &=(1-p)^n(2n+1)+
   \end{align}
   $$

